{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c478c642",
   "metadata": {},
   "source": [
    "Let's use BookNLP (https://github.com/booknlp/booknlp) to extract NER (Person, and Location), and POS (Part of Speech Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f93d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "from booknlp.booknlp import BookNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acedc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"pipeline\":\"entity,quote,supersense,event,coref\", \n",
    "    \"model\":\"big\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaa1f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'big'}\n",
      "--- startup: 10.401 seconds ---\n"
     ]
    }
   ],
   "source": [
    "booknlp = BookNLP(\"en\", model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f8afec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dcb0e5",
   "metadata": {},
   "source": [
    " # 1) A Dark Night's Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f6e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\A Dark Night's Work_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"a_dark_nights_work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c79299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 17.509 seconds ---\n",
      "--- entities: 307.268 seconds ---\n",
      "--- quotes: 0.140 seconds ---\n",
      "--- attribution: 227.973 seconds ---\n",
      "--- name coref: 0.547 seconds ---\n",
      "--- coref: 401.675 seconds ---\n",
      "--- TOTAL (excl. startup): 955.788 seconds ---, 79642 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f3812",
   "metadata": {},
   "source": [
    "# 2) Cranford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c477cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\Cranford_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"cranford\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a6a71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 19.043 seconds ---\n",
      "--- entities: 320.905 seconds ---\n",
      "--- quotes: 0.137 seconds ---\n",
      "--- attribution: 226.214 seconds ---\n",
      "--- name coref: 0.707 seconds ---\n",
      "--- coref: 409.939 seconds ---\n",
      "--- TOTAL (excl. startup): 977.741 seconds ---, 84602 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de150ab4",
   "metadata": {},
   "source": [
    "# 3) Mary Barton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\Mary Barton_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"mary_barton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd91a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 41.077 seconds ---\n",
      "--- entities: 771.971 seconds ---\n",
      "--- quotes: 0.367 seconds ---\n",
      "--- attribution: 692.521 seconds ---\n",
      "--- name coref: 1.622 seconds ---\n",
      "--- coref: 956.162 seconds ---\n",
      "--- TOTAL (excl. startup): 2465.391 seconds ---, 199048 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf63fc",
   "metadata": {},
   "source": [
    "# 4) My Lady Ludlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e1d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\My Lady Ludlow_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"my_lady_ludlow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8bf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 19.067 seconds ---\n",
      "--- entities: 347.655 seconds ---\n",
      "--- quotes: 0.221 seconds ---\n",
      "--- attribution: 181.922 seconds ---\n",
      "--- name coref: 1.003 seconds ---\n",
      "--- coref: 461.557 seconds ---\n",
      "--- TOTAL (excl. startup): 1012.335 seconds ---, 91727 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb1f3b",
   "metadata": {},
   "source": [
    "# 5) North and South"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8591c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\North and South_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"north_and_south\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e024cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 46.499 seconds ---\n",
      "--- entities: 898.036 seconds ---\n",
      "--- quotes: 0.372 seconds ---\n",
      "--- attribution: 851.567 seconds ---\n",
      "--- name coref: 1.272 seconds ---\n",
      "--- coref: 780.827 seconds ---\n",
      "--- TOTAL (excl. startup): 2580.313 seconds ---, 222633 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e595b",
   "metadata": {},
   "source": [
    "# 6) Ruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b11b35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\Ruth_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"ruth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fb31193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 36.534 seconds ---\n",
      "--- entities: 628.964 seconds ---\n",
      "--- quotes: 0.317 seconds ---\n",
      "--- attribution: 539.251 seconds ---\n",
      "--- name coref: 1.138 seconds ---\n",
      "--- coref: 657.741 seconds ---\n",
      "--- TOTAL (excl. startup): 1865.207 seconds ---, 194877 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7f3e2",
   "metadata": {},
   "source": [
    "# 7) Sylvia's Lovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a135c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\Sylvia's Lovers_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"sylvia_lovers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b7e8665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 44.316 seconds ---\n",
      "--- entities: 760.814 seconds ---\n",
      "--- quotes: 0.371 seconds ---\n",
      "--- attribution: 1137.114 seconds ---\n",
      "--- name coref: 1.575 seconds ---\n",
      "--- coref: 712.846 seconds ---\n",
      "--- TOTAL (excl. startup): 2658.815 seconds ---, 233140 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057f8b0",
   "metadata": {},
   "source": [
    "# 8) Wives and Daughters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4238e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\Wives and Daughters_NER.txt\"\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Elizabeth Gaskell\\\\Entities\\\\files' \n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"wives_and_daughters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fa9994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 78.344 seconds ---\n",
      "--- entities: 1313.591 seconds ---\n",
      "--- quotes: 0.679 seconds ---\n",
      "--- attribution: 1841.123 seconds ---\n",
      "--- name coref: 3.798 seconds ---\n",
      "--- coref: 1663.938 seconds ---\n",
      "--- TOTAL (excl. startup): 4905.314 seconds ---, 330511 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee099e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
