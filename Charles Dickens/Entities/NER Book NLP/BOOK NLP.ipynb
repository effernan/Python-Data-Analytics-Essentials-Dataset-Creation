{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c478c642",
   "metadata": {},
   "source": [
    "Let's use BookNLP (https://github.com/booknlp/booknlp) to extract NER (Person, and Location), and POS (Part of Speech Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f93d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "from booknlp.booknlp import BookNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acedc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"pipeline\":\"entity,quote,supersense,event,coref\", \n",
    "    \"model\":\"big\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaa1f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'big'}\n",
      "--- startup: 10.169 seconds ---\n"
     ]
    }
   ],
   "source": [
    "booknlp = BookNLP(\"en\", model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f8afec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dcb0e5",
   "metadata": {},
   "source": [
    " # 1) A Christmas Carol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4f6e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\A Christmas Carol_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"a_christmas_carol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7c79299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 8.531 seconds ---\n",
      "--- entities: 122.248 seconds ---\n",
      "--- quotes: 0.068 seconds ---\n",
      "--- attribution: 138.764 seconds ---\n",
      "--- name coref: 0.077 seconds ---\n",
      "--- coref: 105.211 seconds ---\n",
      "--- TOTAL (excl. startup): 375.079 seconds ---, 37126 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40f3812",
   "metadata": {},
   "source": [
    "# 2) A Tale of Two Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c477cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\A Tale of Two Cities_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"a_tale_of_two_cities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a6a71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 38.547 seconds ---\n",
      "--- entities: 574.319 seconds ---\n",
      "--- quotes: 0.493 seconds ---\n",
      "--- attribution: 725.860 seconds ---\n",
      "--- name coref: 0.585 seconds ---\n",
      "--- coref: 507.843 seconds ---\n",
      "--- TOTAL (excl. startup): 1848.751 seconds ---, 168171 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de150ab4",
   "metadata": {},
   "source": [
    "# 3) Barnaby Rudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "734bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Barnaby Rudge_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"barnaby_rudge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd91a20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 64.328 seconds ---\n",
      "--- entities: 1101.514 seconds ---\n",
      "--- quotes: 0.487 seconds ---\n",
      "--- attribution: 1365.632 seconds ---\n",
      "--- name coref: 1.329 seconds ---\n",
      "--- coref: 1022.441 seconds ---\n",
      "--- TOTAL (excl. startup): 3557.739 seconds ---, 314727 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adf63fc",
   "metadata": {},
   "source": [
    "# 4) Bleak House_NER.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e1d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Bleak House_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"bleak_house\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b8bf746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 91.200 seconds ---\n",
      "--- entities: 1557.437 seconds ---\n",
      "--- quotes: 0.402 seconds ---\n",
      "--- attribution: 2228.918 seconds ---\n",
      "--- name coref: 3.105 seconds ---\n",
      "--- coref: 1464.123 seconds ---\n",
      "--- TOTAL (excl. startup): 5350.024 seconds ---, 434203 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb1f3b",
   "metadata": {},
   "source": [
    "# 5) David Copperfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8591c308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\David Copperfield_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"david_copperfield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e024cdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 90.443 seconds ---\n",
      "--- entities: 1533.780 seconds ---\n",
      "--- quotes: 0.789 seconds ---\n",
      "--- attribution: 1853.288 seconds ---\n",
      "--- name coref: 2.950 seconds ---\n",
      "--- coref: 1505.755 seconds ---\n",
      "--- TOTAL (excl. startup): 4992.302 seconds ---, 441799 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e595b",
   "metadata": {},
   "source": [
    "# 6) Dombey and Son"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b11b35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Dombey and Son_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"Dombey_and_son\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fb31193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 97.076 seconds ---\n",
      "--- entities: 1830.318 seconds ---\n",
      "--- quotes: 0.823 seconds ---\n",
      "--- attribution: 2991.627 seconds ---\n",
      "--- name coref: 4.990 seconds ---\n",
      "--- coref: 1887.042 seconds ---\n",
      "--- TOTAL (excl. startup): 6816.621 seconds ---, 443173 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7f3e2",
   "metadata": {},
   "source": [
    "# 7) Great Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a135c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Great Expectations_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"great_expectations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e8665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 43.979 seconds ---\n",
      "--- entities: 788.883 seconds ---\n",
      "--- quotes: 0.383 seconds ---\n",
      "--- attribution: 1114.923 seconds ---\n",
      "--- name coref: 1.589 seconds ---\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057f8b0",
   "metadata": {},
   "source": [
    "# 8) Hard Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4238e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Hard Times_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"hard_times\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa9994",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab04cbb",
   "metadata": {},
   "source": [
    "# 9) Little Dorrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Little Dorrit_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"little_dorrit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb09e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea667ae8",
   "metadata": {},
   "source": [
    "# 10) Martin Chuzzlewit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Martin Chuzzlewit_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"martin_chuzzlewit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb6a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75ad3b0",
   "metadata": {},
   "source": [
    "# 11) Nicholas Nickleby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901fbaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Nicholas Nickleby_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"nicholas_nickleby\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb392c",
   "metadata": {},
   "source": [
    "# 12) Old_curiosity_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a49ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Old_curiosity_shop_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"old_curiosity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2831f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b4dce5",
   "metadata": {},
   "source": [
    "# 13) Oliver Twist_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Oliver Twist_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"oliver_twist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541cb282",
   "metadata": {},
   "source": [
    "# 14) Our Mutual Friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\Our Mutual Friend_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"our_mutual_friend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5eaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afceba91",
   "metadata": {},
   "source": [
    "# 15) The Battle of Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99025797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\The Battle of Life_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"the_battle_of_life\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97114f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4571fd",
   "metadata": {},
   "source": [
    "# 16) The Chimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\The Chimes_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"the_chimes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6be1dc",
   "metadata": {},
   "source": [
    "# 17) The Cricket on the Hearth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\The Cricket on the Hearth_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"the_cricket_on_the_heart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc05618",
   "metadata": {},
   "source": [
    "# 18) The Haunted Man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\The Haunted Man_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"the_haunted_man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e549a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a1f02",
   "metadata": {},
   "source": [
    "# 19) The Pickwick Papers_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a59cd1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file to process\n",
    "input_file = 'C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\The Pickwick Papers_NER.txt'\n",
    "\n",
    "# Output directory to store resulting files in\n",
    "output_directory= \"C:\\\\Users\\\\usuario\\\\ELENA\\\\it-training uzh\\\\it-training uzh\\\\Python Data Analytics Essentials\\\\Charles Dickens\\\\entities\\\\NER\\\\files\"\n",
    "\n",
    "# File within this directory will be named ${book_id}.entities, ${book_id}.tokens, etc.\n",
    "book_id = \"the_pickwick_papers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15ff2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- spacy: 90.336 seconds ---\n",
      "--- entities: 1460.988 seconds ---\n",
      "--- quotes: 0.719 seconds ---\n",
      "--- attribution: 3960.996 seconds ---\n",
      "--- name coref: 5.183 seconds ---\n",
      "--- coref: 1948.281 seconds ---\n",
      "--- TOTAL (excl. startup): 7470.746 seconds ---, 385672 words\n"
     ]
    }
   ],
   "source": [
    "booknlp.process(input_file, output_directory, book_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee099e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
